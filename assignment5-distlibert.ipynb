{"cells":[{"cell_type":"markdown","metadata":{},"source":["# **NLP Assignment 5**"]},{"cell_type":"markdown","metadata":{},"source":["## PRN: *22070126062*\n","## Name: *Manan Tandel*\n","## Class: *TY AIML A3*  "]},{"cell_type":"markdown","metadata":{},"source":["**Github Link: [GITHUB REPO LINK](https://github.com/manan3044/NLP_Assignment_5)**"]},{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-10-16T12:55:07.676182Z","iopub.status.busy":"2024-10-16T12:55:07.675822Z","iopub.status.idle":"2024-10-16T12:55:15.002342Z","shell.execute_reply":"2024-10-16T12:55:15.001488Z","shell.execute_reply.started":"2024-10-16T12:55:07.676143Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]}],"source":["import json\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import DistilBertTokenizer, DistilBertForQuestionAnswering, AdamW\n","from sklearn.model_selection import train_test_split\n","from tqdm import tqdm\n","from nltk.translate.bleu_score import sentence_bleu\n","import nltk\n","\n","nltk.download('punkt')\n","\n","import logging\n","logging.disable(logging.WARNING)"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-10-16T12:55:49.810003Z","iopub.status.busy":"2024-10-16T12:55:49.809175Z","iopub.status.idle":"2024-10-16T12:55:49.820568Z","shell.execute_reply":"2024-10-16T12:55:49.819692Z","shell.execute_reply.started":"2024-10-16T12:55:49.809942Z"},"trusted":true},"outputs":[],"source":["def load_coqa_data(file_path):\n","    with open(file_path, 'r') as f:\n","        data = json.load(f)\n","    return data['data']\n","\n","class CoQADataset(Dataset):\n","    def __init__(self, data, tokenizer, max_length=512):\n","        self.data = data\n","        self.tokenizer = tokenizer\n","        self.max_length = max_length\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        item = self.data[idx]\n","        context = item['story']\n","        question = item['questions'][0]['input_text']\n","        answer = item['answers'][0]['input_text']\n","\n","        # Tokenize the input\n","        inputs = self.tokenizer.encode_plus(\n","            question,\n","            context,\n","            add_special_tokens=True,\n","            max_length=self.max_length,\n","            padding='max_length',\n","            truncation=True,\n","            return_tensors='pt'\n","        )\n","\n","        # Find the start and end positions of the answer in the tokenized input\n","        input_ids = inputs['input_ids'][0]\n","        answer_tokens = self.tokenizer.encode(answer, add_special_tokens=False)\n","        start_position = None\n","        end_position = None\n","\n","        for i in range(len(input_ids) - len(answer_tokens) + 1):\n","            if input_ids[i:i+len(answer_tokens)].tolist() == answer_tokens:\n","                start_position = i\n","                end_position = i + len(answer_tokens) - 1\n","                break\n","\n","        # If the answer is not found, use the CLS token position as a default\n","        if start_position is None:\n","            start_position = 0\n","            end_position = 0\n","\n","        return {\n","            'input_ids': inputs['input_ids'].flatten(),\n","            'attention_mask': inputs['attention_mask'].flatten(),\n","            'start_positions': torch.tensor(start_position),\n","            'end_positions': torch.tensor(end_position),\n","            'answer': answer\n","        }"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-10-16T12:55:51.903332Z","iopub.status.busy":"2024-10-16T12:55:51.902535Z","iopub.status.idle":"2024-10-16T12:55:53.134326Z","shell.execute_reply":"2024-10-16T12:55:53.132956Z","shell.execute_reply.started":"2024-10-16T12:55:51.903269Z"},"trusted":true},"outputs":[],"source":["data = load_coqa_data('/kaggle/input/qna-dataset/coqa-train-v1.0.json')\n","train_data, test_data = train_test_split(data, test_size=0.3, random_state=42)\n","val_data, test_data = train_test_split(test_data, test_size=0.5, random_state=42)"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-10-16T12:55:56.183320Z","iopub.status.busy":"2024-10-16T12:55:56.182777Z","iopub.status.idle":"2024-10-16T12:55:57.520613Z","shell.execute_reply":"2024-10-16T12:55:57.519780Z","shell.execute_reply.started":"2024-10-16T12:55:56.183279Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ca0668b749174360835137da7416d862","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b1bcad06ae524f4090fcaf644554a8f9","version_major":2,"version_minor":0},"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0eabc50f109c4cc7aeaaeee4dc8697ed","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"af07532f4aca4d9d8a8c6793b388dc0c","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# Initialize tokenizer and model\n","# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n","\n","train_dataset = CoQADataset(train_data, tokenizer)\n","val_dataset = CoQADataset(val_data, tokenizer)\n","test_dataset = CoQADataset(test_data, tokenizer)\n","\n","train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=8)\n","test_loader = DataLoader(test_dataset, batch_size=8)"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-10-16T12:55:58.752501Z","iopub.status.busy":"2024-10-16T12:55:58.752223Z","iopub.status.idle":"2024-10-16T12:55:58.761839Z","shell.execute_reply":"2024-10-16T12:55:58.760838Z","shell.execute_reply.started":"2024-10-16T12:55:58.752464Z"},"trusted":true},"outputs":[],"source":["def train(model, train_loader, optimizer, device):\n","    model.train()\n","    total_loss = 0\n","    progress_bar = tqdm(train_loader, desc=\"Training\")\n","\n","    for batch in progress_bar:\n","        optimizer.zero_grad()\n","        input_ids = batch['input_ids'].to(device)\n","        attention_mask = batch['attention_mask'].to(device)\n","        start_positions = batch['start_positions'].to(device)\n","        end_positions = batch['end_positions'].to(device)\n","\n","        # Forward pass with DistilBERT\n","        outputs = model(input_ids=input_ids, attention_mask=attention_mask, \n","                        start_positions=start_positions, end_positions=end_positions)\n","\n","        # Get the loss from the output\n","        loss = outputs.loss\n","\n","        # Average loss across GPUs (if using multiple)\n","        loss = loss.mean()\n","\n","        total_loss += loss.item()\n","\n","        # Backward pass and optimization step\n","        loss.backward()\n","        optimizer.step()\n","\n","        # Update progress bar with current loss\n","        progress_bar.set_postfix({'loss': loss.item()})\n","\n","    # Return the average loss over all batches\n","    return total_loss / len(train_loader)\n"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-10-16T12:56:00.285843Z","iopub.status.busy":"2024-10-16T12:56:00.285071Z","iopub.status.idle":"2024-10-16T12:56:02.380513Z","shell.execute_reply":"2024-10-16T12:56:02.379797Z","shell.execute_reply.started":"2024-10-16T12:56:00.285789Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d2eda2d6ff924bddaaf86e986081aa04","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]}],"source":["# model = BertForQuestionAnswering.from_pretrained('bert-base-uncased')\n","model = DistilBertForQuestionAnswering.from_pretrained('distilbert-base-uncased')\n","\n","\n","# Set device and move model to device\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model.to(device)\n","\n","# Set optimizer\n","optimizer = AdamW(model.parameters(), lr=5e-5)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-10-16T12:56:02.382297Z","iopub.status.busy":"2024-10-16T12:56:02.382073Z","iopub.status.idle":"2024-10-16T12:56:02.389210Z","shell.execute_reply":"2024-10-16T12:56:02.388377Z","shell.execute_reply.started":"2024-10-16T12:56:02.382266Z"},"trusted":true},"outputs":[],"source":["def validate(model, val_loader, device):\n","    model.eval()\n","    total_loss = 0\n","    progress_bar = tqdm(val_loader, desc=\"Validating\")\n","    with torch.no_grad():\n","        for batch in progress_bar:\n","            input_ids = batch['input_ids'].to(device)\n","            attention_mask = batch['attention_mask'].to(device)\n","            start_positions = batch['start_positions'].to(device)\n","            end_positions = batch['end_positions'].to(device)\n","\n","            # Forward pass with DistilBERT\n","            outputs = model(input_ids=input_ids, attention_mask=attention_mask, \n","                            start_positions=start_positions, end_positions=end_positions)\n","            loss = outputs.loss\n","            total_loss += loss.item()\n","\n","            progress_bar.set_postfix({'loss': loss.item()})\n","\n","    return total_loss / len(val_loader)"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-10-16T12:56:03.123058Z","iopub.status.busy":"2024-10-16T12:56:03.122752Z","iopub.status.idle":"2024-10-16T12:56:03.140296Z","shell.execute_reply":"2024-10-16T12:56:03.138880Z","shell.execute_reply.started":"2024-10-16T12:56:03.123025Z"},"trusted":true},"outputs":[],"source":["# Test function\n","def test(model, test_loader, tokenizer, device):\n","    model.eval()\n","    all_predictions = []\n","    all_answers = []\n","    progress_bar = tqdm(test_loader, desc=\"Testing\")\n","    with torch.no_grad():\n","        for batch in progress_bar:\n","            input_ids = batch['input_ids'].to(device)\n","            attention_mask = batch['attention_mask'].to(device)\n","            answers = batch['answer']\n","\n","            outputs = model(input_ids, attention_mask=attention_mask)\n","            start_scores = outputs.start_logits\n","            end_scores = outputs.end_logits\n","\n","            for i in range(input_ids.shape[0]):\n","                start_index = torch.argmax(start_scores[i])\n","                end_index = torch.argmax(end_scores[i])\n","                prediction = tokenizer.decode(input_ids[i][start_index:end_index+1])\n","                all_predictions.append(prediction)\n","                all_answers.append(answers[i])\n","\n","    bleu_score = calculate_bleu(all_predictions, all_answers)\n","    return bleu_score"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-10-16T12:56:04.698248Z","iopub.status.busy":"2024-10-16T12:56:04.697970Z","iopub.status.idle":"2024-10-16T13:22:41.356782Z","shell.execute_reply":"2024-10-16T13:22:41.355837Z","shell.execute_reply.started":"2024-10-16T12:56:04.698215Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/5\n"]},{"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 630/630 [04:48<00:00,  2.18it/s, loss=3.82]\n","Validating: 100%|██████████| 135/135 [00:27<00:00,  4.88it/s, loss=2.27]\n"]},{"name":"stdout","output_type":"stream","text":["Train Loss: 2.8866, Validation Loss: 2.1153\n","Model saved!\n","**************************************************\n","Epoch 2/5\n"]},{"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 630/630 [04:52<00:00,  2.16it/s, loss=0.981]\n","Validating: 100%|██████████| 135/135 [00:27<00:00,  4.87it/s, loss=2.02]\n"]},{"name":"stdout","output_type":"stream","text":["Train Loss: 1.4879, Validation Loss: 2.0351\n","Model saved!\n","**************************************************\n","Epoch 3/5\n"]},{"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 630/630 [04:52<00:00,  2.16it/s, loss=1.13]  \n","Validating: 100%|██████████| 135/135 [00:27<00:00,  4.87it/s, loss=2.6]  \n"]},{"name":"stdout","output_type":"stream","text":["Train Loss: 0.7604, Validation Loss: 2.4218\n","Validation Loss Increased. Model Not Saved.\n","**************************************************\n","Epoch 4/5\n"]},{"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 630/630 [04:52<00:00,  2.16it/s, loss=0.187] \n","Validating: 100%|██████████| 135/135 [00:27<00:00,  4.86it/s, loss=2.65] \n"]},{"name":"stdout","output_type":"stream","text":["Train Loss: 0.4304, Validation Loss: 2.9000\n","Validation Loss Increased. Model Not Saved.\n","**************************************************\n","Epoch 5/5\n"]},{"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 630/630 [04:52<00:00,  2.16it/s, loss=0.273] \n","Validating: 100%|██████████| 135/135 [00:27<00:00,  4.88it/s, loss=3.63] "]},{"name":"stdout","output_type":"stream","text":["Train Loss: 0.2623, Validation Loss: 3.3733\n","Validation Loss Increased. Model Not Saved.\n","**************************************************\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["# Training loop\n","num_epochs = 5\n","best_loss = float('inf')\n","for epoch in range(num_epochs):\n","    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n","    train_loss = train(model, train_loader, optimizer, device)\n","    val_loss = validate(model, val_loader, device)\n","    print(f\"Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}\")\n","    if val_loss < best_loss:\n","        best_loss = val_loss\n","        torch.save(model.state_dict(), 'distilbert_qa_model.pth')\n","        print(\"Model saved!\")\n","    else:\n","        print(\"Validation Loss Increased. Model Not Saved.\")\n","    print(\"*\" * 50)"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-10-16T13:22:47.044021Z","iopub.status.busy":"2024-10-16T13:22:47.043731Z","iopub.status.idle":"2024-10-16T13:22:47.049569Z","shell.execute_reply":"2024-10-16T13:22:47.048671Z","shell.execute_reply.started":"2024-10-16T13:22:47.043986Z"},"trusted":true},"outputs":[],"source":["# Calculate BLEU score\n","def calculate_bleu(predictions, references):\n","    bleu_scores = []\n","    for pred, ref in zip(predictions, references):\n","        bleu_scores.append(sentence_bleu([ref.split()], pred.split()))\n","    return sum(bleu_scores) / len(bleu_scores)\n"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-10-16T13:22:48.825299Z","iopub.status.busy":"2024-10-16T13:22:48.825035Z","iopub.status.idle":"2024-10-16T13:23:17.063416Z","shell.execute_reply":"2024-10-16T13:23:17.062558Z","shell.execute_reply.started":"2024-10-16T13:22:48.825268Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Testing: 100%|██████████| 135/135 [00:28<00:00,  4.80it/s]"]},{"name":"stdout","output_type":"stream","text":["BLEU Score: 0.1330\n"]},{"name":"stderr","output_type":"stream","text":["\n","/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \n","Corpus/Sentence contains 0 counts of 2-gram overlaps.\n","BLEU scores might be undesirable; use SmoothingFunction().\n","  warnings.warn(_msg)\n","/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \n","Corpus/Sentence contains 0 counts of 3-gram overlaps.\n","BLEU scores might be undesirable; use SmoothingFunction().\n","  warnings.warn(_msg)\n","/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \n","Corpus/Sentence contains 0 counts of 4-gram overlaps.\n","BLEU scores might be undesirable; use SmoothingFunction().\n","  warnings.warn(_msg)\n"]}],"source":["# Test the model\n","bleu_score = test(model, test_loader, tokenizer, device)\n","print(f\"BLEU Score: {bleu_score:.4f}\")\n"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":5883900,"sourceId":9636743,"sourceType":"datasetVersion"}],"dockerImageVersionId":30787,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
